### Overview
Challenge is to build multilingual models with English-only training data to identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion. If these toxic contributions can be identified, we could have a safer, more collaborative internet.

### Data
* Train data is entirely in English and comes from Civil Comments or Wikipedia talk page edits.
* Test data contains comments composed of multiple non-English languages.
* Predict the probability that a comment is toxic. A toxic comment would receive a 1.0. A benign, non-toxic comment would receive a 0.0. In the test set, all comments are classified as either a 1.0 or a 0.0.








